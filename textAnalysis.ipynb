{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1stkmjkxwN1fhg-uQDJ_blFmMqDu2QbTe",
      "authorship_tag": "ABX9TyNQNpnGHjonX8VSTjlQsGcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrorvelle/ErlangC-Calculation/blob/master/textAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdxvkPltZFQI"
      },
      "source": [
        "Set up way to extract mp3 from a website and convert to .wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMsrwXIbm_Im"
      },
      "source": [
        "# Access Azure DB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Guz5kx8pb9BU",
        "outputId": "f36faeb3-6f74-44b3-b353-1b7fa87ef01b"
      },
      "source": [
        "!pip install mysql.connector\n",
        "!pip3 install SpeechRecognition pydub\n",
        "import mysql.connector\n",
        "from mysql.connector import errorcode\n",
        "import pandas as pd\n",
        "import speech_recognition as sr \n",
        "import os \n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "#[!INCLUDE[applies-to-mysql-single-server](includes/applies-to-mysql-single-server.md)]\n",
        "config = {\n",
        "  'host':'sermons.mysql.database.azure.com',\n",
        "  'user':'trevorpollo@sermons',\n",
        "  'password':'PITW78twias!',\n",
        "  'database':'sermons',\n",
        "  #'client_flags': [mysql.connector.ClientFlag.SSL],\n",
        "  #'ssl_ca': '/var/wwww/html/DigiCertGlobalRootG2.crt.pem'\n",
        "}\n",
        "\n",
        "# Construct connection string\n",
        "\n",
        "#[!INCLUDE[applies-to-mysql-single-server](includes/applies-to-mysql-single-server.md)]\n",
        "try:\n",
        "   conn = mysql.connector.connect(**config)\n",
        "   print(\"Connection established\")\n",
        "except mysql.connector.Error as err:\n",
        "  if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
        "    print(\"Something is wrong with the user name or password\")\n",
        "  elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
        "    print(\"Database does not exist\")\n",
        "  else:\n",
        "    print(err)\n",
        "else:\n",
        "  cursor = conn.cursor()\n",
        "\n",
        "#cursor.execute(\"CREATE DATABASE sermons;\")"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /root/.cache/pip/wheels/8c/83/a1/f8b6d4bb1bd6208bbde1608bbfa7557504bed9eaf2ecf8c175/mysql_connector-2.2.9-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: mysql.connector\n",
            "Successfully installed mysql.connector\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Connection established\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I67JusSVyaSo"
      },
      "source": [
        ""
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ7e0OFCb_2l"
      },
      "source": [
        "# Function to process audio file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX8u9UoJY9-M"
      },
      "source": [
        "def get_large_audio_transcription(path, df):\n",
        "          \"\"\"\n",
        "          Splitting the large audio file into chunks\n",
        "          and apply speech recognition on each of these chunks\n",
        "          \"\"\"\n",
        "\n",
        "          # open the audio file using pydub\n",
        "          sound = AudioSegment.from_wav(path)  \n",
        "          # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "          chunks = split_on_silence(sound,\n",
        "              # experiment with this value for your target audio file\n",
        "              min_silence_len = 750,\n",
        "              # adjust this per requirement\n",
        "              silence_thresh = sound.dBFS-14,\n",
        "              # keep the silence for 1 second, adjustable as well\n",
        "              keep_silence=1000,\n",
        "          )\n",
        "          folder_name = \"audio-chunks\"\n",
        "          # create a directory to store the audio chunks\n",
        "          if not os.path.isdir(folder_name):\n",
        "              os.mkdir(folder_name)\n",
        "          whole_text = \"\"\n",
        "          # process each chunk \n",
        "          for i, audio_chunk in enumerate(chunks, start=1):\n",
        "              # export audio chunk and save it in\n",
        "              # the `folder_name` directory.\n",
        "              chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "              audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "              # recognize the chunk\n",
        "              with sr.AudioFile(chunk_filename) as source:\n",
        "                  audio_listened = r.record(source)\n",
        "                  # try converting it to text\n",
        "                  try:\n",
        "                      text = r.recognize_google(audio_listened)\n",
        "                  except sr.UnknownValueError as e:\n",
        "                      print(\"Error:\", str(e))\n",
        "                  else:\n",
        "                      text = f\"{text.capitalize()}. \"\n",
        "                      #print(chunk_filename, \":\", text)\n",
        "                      whole_text += text\n",
        "                      df = df.append({'church' : church, 'date' : sermon, 'pastor' : pastor, 'text' : text}, \n",
        "                      ignore_index = True)\n",
        "          \n",
        "          !pip install pymysql\n",
        "          import sqlalchemy as sal\n",
        "          from sqlalchemy import create_engine\n",
        "\n",
        "          engine = create_engine('mysql+pymysql://trevorpollo@sermons:PITW78twias!@sermons.mysql.database.azure.com:3306/sermons', echo=False)\n",
        "          cnx = engine.raw_connection()\n",
        "          data = df\n",
        "          data.to_sql(name='sermons', con=engine, if_exists = 'append', index=False)\n",
        "\n",
        "          import numpy as np\n",
        "\n",
        "          #keyword search\n",
        "          abortionarray = np.array(['abortion', 'abort', 'prolife', 'prochoice', 'pro life', 'pro choice', 'abort', 'fetus', 'unborn', 'preborn', 'embryo', 'life begin', 'planned pa','pregnancy', 'pregnant', 'pregna', 'conception', 'conceived', 'unplanned'])\n",
        "          racearray = np.array(['social jutice', 'equality', 'racism', 'race', 'bigotry', 'discrimina', 'prejudice', 'slavery', 'segregation', 'systemic', 'hateful', 'black lives', 'brutality', 'militia'])\n",
        "          sexsinarray = np.array(['porn', 'adultery', 'cheat', 'rape', 'modesty', 'modest', 'sex', 'fetish', 'grope', 'masturba', 'lust', 'polygamy', 'gay', 'lesbian', 'lgb', 'queer', 'homo', 'homos', 'marriage', 'pre mar', 'sodom', 'pervert'])\n",
        "          politicsarray = np.array(['democrat', 'republican', 'politic', 'elected', 'president', 'vote', 'congress', 'war', 'equality', 'equity', 'constitution', 'independence', 'freedom', 'rights', 'liberty', 'equality', 'feminis'])\n",
        "          gayarray = np.array(['gay', 'lesbi', 'homos', 'homo', 'same sex', 'attraction', 'lgb', 'rainbow', 'queer'])\n",
        "          feministarray = np.array(['complimen', 'household', 'femini', 'role', 'head of h', 'spiritual le', 'male', 'female', 'gender', 'women', 'men'])\n",
        "\n",
        "          #the resulting counts will go into a sql table with the key being concat('DateChurchPastor')\n",
        "          abortion_counter = 0\n",
        "          race_counter = 0\n",
        "          sexsin_counter = 0\n",
        "          political_counter = 0\n",
        "          gay_counter = 0\n",
        "          feminism_counter = 0\n",
        "\n",
        "          #create np array for faster processing\n",
        "          dfarray = np.array(df.text)\n",
        "\n",
        "          #loop through text of a sermon for keywords\n",
        "          for i in dfarray:\n",
        "            if any(ele in i for ele in abortionarray) == True:\n",
        "              abortion_counter += 1\n",
        "            elif any(ele in i for ele in racearray) == True:\n",
        "              race_counter += 1\n",
        "            elif any(ele in i for ele in sexsinarray) == True:\n",
        "              sexsin_counter += 1\n",
        "            elif any(ele in i for ele in politicsarray) == True:\n",
        "              political_counter += 1\n",
        "            elif any(ele in i for ele in gayarray) == True:\n",
        "              gay_counter += 1\n",
        "            elif any(ele in i for ele in feministarray) == True:\n",
        "              feminism_counter += 1\n",
        "\n",
        "          print('abortion refs ' + str(abortion_counter))\n",
        "\n",
        "          if abortion_counter\n",
        "          \n",
        "\n",
        "          \n",
        "          resultingdata = {'sermondate':[sermon], 'sermonchurch':[church], 'sermonpastor':[pastor], \\\n",
        "                           'abortioncount':[abortion_counter], 'race':[race_counter], 'sex':[sexsin_counter], 'feminism':[feminism_counter], 'gay':[gay_counter], 'political':[political_counter]}\n",
        "          df2 = pd.DataFrame(resultingdata)\n",
        "          engine = create_engine('mysql+pymysql://trevorpollo@sermons:PITW78twias!@sermons.mysql.database.azure.com:3306/sermons', echo=False)\n",
        "          cnx = engine.raw_connection()\n",
        "          data = df2\n",
        "          data.to_sql(name='sermonstats', con=engine, if_exists = 'append', index=False)\n",
        "\n",
        "\n",
        "          # return the text for all chunks detected\n",
        "          #return whole_text\n",
        "          return pd.DataFrame(df)\n",
        "\n",
        "         "
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYouecr1QPTc"
      },
      "source": [
        "import requests \n",
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import pandas as pd\n",
        "import speech_recognition as sr \n",
        "import os \n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "from csv import reader\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('/content/drive/MyDrive/sermonlists.csv', 'r') as read_obj:\n",
        "    sermonsdf = pd.read_csv('/content/drive/MyDrive/sermonlists.csv')\n",
        "    #print(sermonsdf.dtypes)\n",
        "    # Check file as empty\n",
        "        # Iterate over each row after the header in the csv\n",
        "    for row in sermonsdf.itertuples():\n",
        "      file_url = str(row.path)\n",
        "      r = requests.get(file_url, stream = True) \n",
        "      with open(\"file_url.mp3\", \"wb\") as file: \n",
        "        for block in r.iter_content(chunk_size = 1024):\n",
        "              if block: \n",
        "                  file.write(block)\n",
        "      src = 'file_url.mp3'\n",
        "      dst = \"/content/drive/MyDrive/\"+str(row.date)+\".wav\"\n",
        "\n",
        "      # convert wav to mp3                                                            \n",
        "      sound = AudioSegment.from_mp3(src)\n",
        "      sound.export(dst, format=\"wav\")\n",
        "\n",
        "      !touch dst\n",
        "      os.remove(src)\n",
        "      \n",
        "      \n",
        "      path = dst\n",
        "      pastor = row.pastor\n",
        "      church = row.church\n",
        "      sermon = row.date\n",
        "      df = pd.DataFrame(columns = ['church','pastor','date','text'])\n",
        "\n",
        "\n",
        "\n",
        "      !pip3 install SpeechRecognition pydub\n",
        "      # importing libraries \n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "      # create a speech recognition object\n",
        "      r = sr.Recognizer()\n",
        "\n",
        "\n",
        "      # a function that splits the audio file into chunks\n",
        "      # and applies speech recognition\n",
        "      \n",
        "      df = get_large_audio_transcription(path, df)\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}